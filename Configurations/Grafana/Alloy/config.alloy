////////////////////////////////////////////////////////////
// GLOBAL LOGGING
////////////////////////////////////////////////////////////
logging {
  level  = "info"
  format = "logfmt"
}

////////////////////////////////////////////////////////////
// OTLP RECEIVER
////////////////////////////////////////////////////////////
otelcol.receiver.otlp "default" {
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  http {
    endpoint = "0.0.0.0:4318"
  }

  output {
    traces = [otelcol.processor.attributes.traces.input]
    logs   = [otelcol.processor.batch.logs.input]
  }
}

////////////////////////////////////////////////////////////
// TRACE ATTRIBUTE PROCESSING
////////////////////////////////////////////////////////////
otelcol.processor.attributes "traces" {
  // Add deployment environment
  action {
    key    = "deployment.environment"
    value  = "prod"
    action = "upsert"
  }

  // Add deployment platform
  action {
    key    = "deployment.platform"
    value  = "docker"
    action = "upsert"
  }

  // Remove sensitive headers
  action {
    key    = "http.request.header.authorization"
    action = "delete"
  }

  action {
    key    = "http.request.header.cookie"
    action = "delete"
  }

  output {
    traces = [otelcol.processor.tail_sampling.traces.input]
  }
}

////////////////////////////////////////////////////////////
// TRACE TAIL SAMPLING
////////////////////////////////////////////////////////////
otelcol.processor.tail_sampling "traces" {
  decision_wait = "10s"

  policy {
    name = "errors"
    type = "status_code"

    status_code {
      status_codes = ["ERROR"]
    }
  }

  policy {
    name = "slow"
    type = "latency"

    latency {
      threshold_ms = 1500
    }
  }

  policy {
    name = "baseline"
    type = "probabilistic"

    probabilistic {
      sampling_percentage = 5
    }
  }

  output {
    traces = [otelcol.processor.batch.traces.input]
  }
}

////////////////////////////////////////////////////////////
// TRACE BATCH → TEMPO
////////////////////////////////////////////////////////////
otelcol.processor.batch "traces" {
  timeout              = "5s"
  send_batch_size      = 100
  send_batch_max_size  = 100

  output {
    traces = [otelcol.exporter.otlp.tempo.input]
  }
}

otelcol.exporter.otlp "tempo" {
  client {
    endpoint = "gf-tempo:4317"

    tls {
      insecure = true
    }
  }
}

////////////////////////////////////////////////////////////
// LOG BATCH → LOKI
////////////////////////////////////////////////////////////
otelcol.processor.batch "logs" {
  timeout              = "5s"
  send_batch_size      = 100
  send_batch_max_size  = 100

  output {
    logs = [otelcol.exporter.loki.otlp.input]
  }
}

otelcol.exporter.loki "otlp" {
  forward_to = [loki.process.otlp.receiver]
}

////////////////////////////////////////////////////////////
// OTLP LOG PROCESSING
////////////////////////////////////////////////////////////
loki.process "otlp" {
  stage.json {
    expressions = {
      level   = "severity_text",
      traceId = "trace_id",
      spanId  = "span_id",
    }
  }

  stage.labels {
    values = {
      service_name      = "attributes.service.name",
      service_namespace = "attributes.service.namespace",
      deployment_env    = "attributes.deployment.environment",
      severity          = "severity_text",
      trace_id          = "traceId",
    }
  }

  stage.static_labels {
    values = {
      job        = "otlp",
      source     = "application",
      env        = "prod",
    }
  }

  forward_to = [loki.write.default.receiver]
}

////////////////////////////////////////////////////////////
// DOCKER DISCOVERY
////////////////////////////////////////////////////////////
discovery.docker "linux" {
  host = "unix:///var/run/docker.sock"
}

////////////////////////////////////////////////////////////
// DOCKER LOGS
////////////////////////////////////////////////////////////
loki.source.docker "containers" {
  host    = "unix:///var/run/docker.sock"
  targets = discovery.docker.linux.targets

  labels = {
    job = "docker",
  }

  forward_to = [loki.process.docker.receiver]
}

loki.process "docker" {
  stage.drop {
    older_than = "24h"
  }

  stage.labels {
    values = {
      service_name = "container.name",
      container_id = "container.id",
      image        = "container.image.name",
    }
  }

  stage.static_labels {
    values = {
      env    = "prod",
      source = "docker",
    }
  }

  forward_to = [loki.write.default.receiver]
}

////////////////////////////////////////////////////////////
// LOKI WRITE
////////////////////////////////////////////////////////////
loki.write "default" {
  endpoint {
    url = "http://loki:3100/loki/api/v1/push"
  }
}

////////////////////////////////////////////////////////////
// CONTAINER METRICS (CADVISOR)
////////////////////////////////////////////////////////////
prometheus.exporter.cadvisor "docker" {
  docker_only      = true
  storage_duration = "2m"
}

prometheus.relabel "cadvisor_relabel" {
  rule {
    source_labels = ["__meta_docker_container_name"]
    regex         = "/(.*)"
    target_label  = "container"
    replacement   = "$1"
  }

  rule {
    source_labels = ["__meta_docker_container_image"]
    regex         = "docker.io/(.*):.*|(.*)"
    target_label  = "image"
    replacement   = "$1$2"
  }

  rule {
    target_label = "env"
    replacement  = "prod"
  }

  // Remove high-cardinality filesystem metrics
  rule {
    source_labels = ["__name__"]
    regex         = "container_fs_.*"
    action        = "drop"
  }

  // Keep only useful container metrics
  rule {
    source_labels = ["__name__"]
    regex         = "container_cpu_usage_seconds_total|container_memory_usage_bytes|container_memory_working_set_bytes|container_network_.*|container_spec_.*"
    action        = "keep"
  }

  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "cadvisor" {
  targets         = prometheus.exporter.cadvisor.docker.targets
  scrape_interval = "15s"
  scrape_timeout  = "10s"

  forward_to = [prometheus.relabel.cadvisor_relabel.receiver]
}

////////////////////////////////////////////////////////////
// HOST METRICS
////////////////////////////////////////////////////////////
prometheus.exporter.unix "node" {
  // Optional: Enable specific collectors to reduce load
  // enabled_collectors = ["cpu", "filesystem", "memory", "diskstats", "loadavg"]
}

prometheus.relabel "node_relabel" {
  rule {
    target_label = "env"
    replacement  = "prod"
  }

  // Remove high-frequency time metrics
  rule {
    source_labels = ["__name__"]
    regex         = "node_time_.*"
    action        = "drop"
  }

  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "node" {
  targets         = prometheus.exporter.unix.node.targets
  scrape_interval = "30s"
  scrape_timeout  = "10s"

  forward_to = [prometheus.relabel.node_relabel.receiver]
}

////////////////////////////////////////////////////////////
// INFRA METRICS
////////////////////////////////////////////////////////////
prometheus.relabel "infra_relabel" {
  rule {
    target_label = "env"
    replacement  = "prod"
  }

  forward_to = [prometheus.remote_write.default.receiver]
}

prometheus.scrape "infra" {
  targets = [
    { "__address__" = "tempo:3200",      "job" = "tempo" },
    { "__address__" = "loki:3100",       "job" = "loki" },
    { "__address__" = "prometheus:9090", "job" = "prometheus" },
    { "__address__" = "grafana:3000",    "job" = "grafana" },
  ]

  forward_to = [prometheus.relabel.infra_relabel.receiver]
}

////////////////////////////////////////////////////////////
// ALLOY METRICS
////////////////////////////////////////////////////////////
prometheus.scrape "alloy" {
  targets = [
    { "__address__" = "127.0.0.1:12345", "job" = "alloy" },
  ]

  forward_to = [prometheus.remote_write.default.receiver]
}

////////////////////////////////////////////////////////////
// REMOTE WRITE
////////////////////////////////////////////////////////////
prometheus.remote_write "default" {
  endpoint {
    url = "http://prometheus:9090/api/v1/write"
  }
}