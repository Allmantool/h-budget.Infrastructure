name: monitoring
services:
  prometheus:
    container_name: prometheus
    image: prom/prometheus:v3.8.0
    networks:
      - rates-api-network
      - accounting-api-network
      - mongo-network
      - kafka-net
      - mssql-network
      - redis-network
      - ui-network
      - event-store-db-net
      - shared-monitoring-net
    ports:
      - 9090:9090
    volumes:
      - ${PROMETHEUS_CONFIG}:/etc/prometheus/prometheus.yml
      # - ${PROMETHEUS_DATA}:/prometheus
      - prometheus-data:/prometheus
    depends_on:
      - homebudget-rates-api
      - homebudget-accounting-api
      - gateway-api
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "512m"

  tempo:
    image: grafana/tempo:latest # Use stable version instead of specific commit
    container_name: tempo
    ports:
      - "3200:3200" # Query API (unique)
      - "4319:4317" # OTLP gRPC - changed from 4317 to 4319 to avoid conflict
      - "4320:4318" # OTLP HTTP - changed from 4318 to 4320 to avoid conflict
      - "9411:9411" # Zipkin (optional)
    volumes:
      - ${GF_TEMPO_STORAGE}:/var/tempo
      - ${GF_TEMPO_CONFIG}:/etc/tempo.yaml
    command: ["--config.file=/etc/tempo.yaml"]
    networks:
      - rates-api-network
      - accounting-api-network
      - mongo-network
      - kafka-net
      - mssql-network
      - redis-network
      - ui-network
      - shared-monitoring-net

  otel-collector:
    image: otel/opentelemetry-collector:latest
    container_name: otel-collector
    command: ["--config=/etc/otel-collector.yaml"]
    volumes:
      - ${GF_COLLECTOR_CONFIG}:/etc/otel-collector.yaml
    ports:
      - "4317:4317" # OTLP gRPC - .NET apps send here
      - "4318:4318" # OTLP HTTP - .NET apps can also use this
      - "8888:8888" # Metrics
      - "8889:8889" # Health check
    networks:
      - rates-api-network
      - accounting-api-network
      - mongo-network
      - kafka-net
      - mssql-network
      - redis-network
      - ui-network
      - shared-monitoring-net

  grafana-tempo-query:
    image: grafana/tempo-query:latest
    container_name: tempo-query
    ports:
      - "16686:16686" # Jaeger UI
    environment:
      - TEMPO=http://tempo:3200
      - QUERY_TIMEOUT=30s
    networks:
      - rates-api-network
      - accounting-api-network
      - mongo-network
      - kafka-net
      - mssql-network
      - redis-network
      - ui-network
      - shared-monitoring-net

  grafana:
    container_name: grafana
    image: grafana/grafana:12.3.0-ubuntu
    networks:
      - rates-api-network
      - accounting-api-network
      - mongo-network
      - kafka-net
      - mssql-network
      - redis-network
      - ui-network
      - shared-monitoring-net
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_INSTALL_PLUGINS: "https://github.com/raintank/crate-datasource/archive/master.zip;crate-datasource,grafana-clock-panel,grafana-worldmap-panel,natel-plotly-panel"
    ports:
      - 3000:3000
    volumes:
      - ${GRAFANA_CONFIG}:/etc/grafana/provisioning.yml
      - gf-logs:/var/log/grafana
      - gf-data:/var/lib/grafana
      - gf-provisioning:/etc/grafana/provisioning
      # - ${GF_PATHS_LOGS}:/var/log/grafana
      # - ${GF_STORAGE}:/var/lib/grafana
      # - ${GF_PATHS_PROVISIONING}:/etc/grafana/provisioning
    depends_on:
      - prometheus
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "1g"

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    pid: host
    command:
      - "--path.rootfs=/host"
    volumes:
      - "${DOCKER_NODE_PATHS_LOGS}:/host:ro,rslave"
    ports:
      - "9100:9100"
    networks:
      - shared-monitoring-net
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "128m"

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.0
    container_name: cadvisor
    privileged: true
    environment:
    - DOCKER_API_VERSION=1.52 
    command:
      - "--containerd=/run/containerd/containerd.sock"
      - "--docker_only=false"
      - "--housekeeping_interval=10s"
    volumes:
    - /:/rootfs:ro
    - /var/run:/var/run:rw
    - /sys:/sys:ro
    - /sys/fs/cgroup:/sys/fs/cgroup:ro
    - /var/lib/docker:/var/lib/docker:ro
    - /run/containerd/containerd.sock:/run/containerd/containerd.sock:ro
    - /var/run/docker.sock:/var/run/docker.sock:ro  # Mount Docker socket to cAdvisor
    ports:
      - "8080:8080"
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "4"
          memory: "512m"

  mongo-db-exporter:
    image: percona/mongodb_exporter:2.37
    container_name: prometheus-mongo-db-exporter
    command:
      - "--mongodb.global-conn-pool"
      - "--collector.diagnosticdata"
      - "--discovering-mode"
      - "--compatible-mode"
      - "--mongodb.collstats-colls=admin.companies,admin.restaurants"
      - "--collect-all"
    environment:
      - MONGODB_URI=mongodb://mongoadmin:${MONGO_DB_PASSWORD}@shared-mongo-db:27017/?maxPoolSize=1000&waitQueueTimeoutMS=15000
    restart: unless-stopped
    ports:
      - "9216:9216"
      - "17001:17001"
    networks:
      - mongo-network
      - shared-monitoring-net
    depends_on:
      - prometheus
      - shared-mongo-db
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "128m"

  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.9.0
    container_name: prometheus-kafka-exporter
    command:
      - "--kafka.server=kafka:29092"
    ports:
      - 9308:9308
    networks:
      - kafka-net
      - shared-monitoring-net
    depends_on:
      - prometheus
      - kafka
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 30
        delay: 15s
        window: 1080s
      resources:
        limits:
          cpus: "1"
          memory: "128m"

  mssql-exporter:
    image: allmantool/sql-monitoring-exporter:0.0.8
    container_name: prometheus-mssql-exporter
    environment:
      SERVER: ${SQL_SERVER}
      PORT: ${SQL_SERVER_2025_PORT}
      USERNAME: SA
      PASSWORD: ${WMS_SQL_PASSWORD}
    ports:
      - 4000:4000
    networks:
      - mssql-network
      - shared-monitoring-net
    depends_on:
      - prometheus
      - ${SQL_SERVER}
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "256m"

  redis-exporter:
    image: oliver006/redis_exporter:v1.80.1
    container_name: prometheus-redis-exporter
    environment:
      REDIS_ADDR: redis_server:6379
    ports:
      - 9121:9121
    networks:
      - redis-network
      - shared-monitoring-net
    depends_on:
      - prometheus
      - redis_server
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "128m"

  nginx-exporter:
    image: nginx/nginx-prometheus-exporter:1.5.1
    container_name: nginx-exporter
    command:
      - "--nginx.scrape-uri=http://localhost:5407/stub_status"
    ports:
      - 9113:9113
    networks:
      - ui-network
    depends_on:
      - prometheus
      - homebudget-ui
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "128m"

  event-store-db-exporter:
    image: marcinbudny/eventstore_exporter:0.16.0
    container_name: event-store-db-exporter
    environment:
      - EVENTSTORE_URL=http://event-store-db:2113
      - EVENTSTORE_USER=admin
      - EVENTSTORE_PASSWORD=changeit
      - ENABLE_PARKED_MESSAGES_STATS=True
    ports:
      - 9448:9448
    networks:
      - event-store-db-net
      - shared-monitoring-net
    depends_on:
      - prometheus
      - event-store-db
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 10
        delay: 5s
        window: 180s
      resources:
        limits:
          cpus: "1"
          memory: "128m"
